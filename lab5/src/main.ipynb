{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as rd \n",
    "import pickle as pk\n",
    "\n",
    "from Judge.Score import *   # 评价指标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ft_origin = pd.read_csv('./Datasets/train_feature.csv')\n",
    "df_lb_origin = pd.read_csv('./Datasets/train_label.csv') \n",
    "\n",
    "# df_origin = pd.concat([df_ft_origin, df_lb_origin],axis=1)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据预处理\n",
    "首先进行数据的预处理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 115)\n"
     ]
    }
   ],
   "source": [
    "from Preprocessing import Tools as M_TOOL\n",
    "from Preprocessing import PCA as M_PCA\n",
    "\n",
    "df_ft = M_TOOL.random_FillMissingData(df_ft_origin)\n",
    "df_lb = M_TOOL.random_FillMissingData(df_lb_origin)\n",
    "\n",
    "df_ft = M_TOOL.Normalization(df_ft).values\n",
    "\n",
    "PCA_model = M_PCA.PCA(df_ft)\n",
    "df_ft = pd.DataFrame(PCA_model.reduce_dimension())\n",
    "# print(df.head())\n",
    "df = pd.concat([df_ft, df_lb], axis=1)\n",
    "df.drop_duplicates(inplace=True)\n",
    "print(df.shape)\n",
    "\n",
    "\n",
    "X_train, y_train, X_test, Y_test = M_TOOL.random_Split_data(df)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型训练与预测\n",
    "\n",
    "接下来，我们将分别使用线性回归模型、决策树模型、神经网络模型、支持向量机以及 XGBoost 等分类模型对数据集进行训练，并在验证集上进行预测。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "线性回归模型分类准确度为 0.25560000000000005\n",
      "SKLearn 分类准确度为 0.24160000000000004\n"
     ]
    }
   ],
   "source": [
    "from Methods import LinearReg as M_LR\n",
    "# 线性回归模型\n",
    "\n",
    "model_liner = M_LR.LinearRegression(X_train, y_train)\n",
    "model_liner.fit()\n",
    "# model_liner.save()\n",
    "# model_liner = pk.load(open(\"./model/Model_LinearReg_2022_12_24_21_07_58.dat\", \"rb\"))    # 使用已保存的模型\n",
    "\n",
    "pre = model_liner.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "acc = Accuracy(pre, Y_test)\n",
    "print(\"线性回归模型分类准确度为 {}\".format(acc))\n",
    "\n",
    "\n",
    "# 与 Sklearn 比较\n",
    "from sklearn.linear_model import LinearRegression as LR  \n",
    "model_liner_skl = LR().fit(X_train, y_train)\n",
    "pre_skl = model_liner_skl.predict(X_test)\n",
    "\n",
    "acc = Accuracy(pre_skl, Y_test)\n",
    "print(\"SKLearn 分类准确度为 {}\".format(acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from Methods import RegTree as M_RT\n",
    "# # 回归树模型\n",
    "\n",
    "# m, n = y_train.shape \n",
    "# y_t = np.zeros((m, n))\n",
    "# model_regtree = M_RT.RegressionTree(X_train, y_train, y_t)\n",
    "# default_parameters = {\n",
    "#     \"lamda\": 2,             # Hyperparameters\n",
    "#     \"gamma\": 1e-6,          # Hyperparameters\n",
    "#     \"gain_delta\": 0,        # The minimum gain\n",
    "#     \"max_depth\": 3,\n",
    "#     \"max_leaves\": 100,\n",
    "#     \"max_nodes\": 1000,\n",
    "#     \"min_samples\": 10,      # Minimum number of samples on a leaf\n",
    "#     \"min_feature_dif\": 5,   # The minimum number of different value for current feature\n",
    "#     \"if_silent\": 0\n",
    "# }\n",
    "# model_regtree.fit(default_parameters)\n",
    "# pre = model_regtree.predict(X_test)\n",
    "\n",
    "# acc = Accuracy(pre, Y_test)\n",
    "# print(\"回归树模型分类准确度为 {}\".format(acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from Methods import SVM as M_SVM\n",
    "# # 支持向量机模型\n",
    "\n",
    "# model_SVM = M_SVM.SupportVectorMachine(X_train, y_train)\n",
    "# model_SVM.fit(max_times=500, ifsilent=True)\n",
    "# pre = model_SVM.predict(X_test)\n",
    "\n",
    "# acc = Accuracy(pre, Y_test)\n",
    "# print(\"SVM 模型分类准确度为 {}\".format(acc))\n",
    "\n",
    "\n",
    "# # 与 SKLearn 比较\n",
    "# from sklearn import svm \n",
    "# model = svm.SVC(kernel='linear')\n",
    "# model.fit(X_train, y_train.flatten())\n",
    "# pre_skl = model.predict(X_test).reshape(-1, 1)\n",
    "\n",
    "# acc = Accuracy(pre_skl, Y_test)\n",
    "# print(\"SKLearn 分类准确度为 {}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from Methods import XGBoost as M_XGB\n",
    "# # XGBoost 模型\n",
    "\n",
    "# model_XGB = M_XGB.XGBoost(X_train, y_train)\n",
    "# tree_parameters = {\n",
    "#     \"lamda\": 1,         \n",
    "#     \"gamma\": 0,          \n",
    "#     \"gain_delta\": 0,     \n",
    "#     \"max_depth\": 2,\n",
    "#     \"max_leaves\": 100,\n",
    "#     \"max_nodes\": 1000,\n",
    "#     \"min_samples\": 3,      \n",
    "#     \"min_feature_dif\": 3,  \n",
    "#     \"if_silent\": 0,\n",
    "# }\n",
    "# model_XGB.fit(T=35, tree_parameters=tree_parameters, min_train_err=1e-4)\n",
    "# pre = model_XGB.predict(X_test)\n",
    "\n",
    "# acc = Accuracy(pre, Y_test)\n",
    "# print(\"线性回归模型分类准确度为 {}\".format(acc))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2469a70536e4d2335a2ea8907942d0699c37342a371ac185bdb5b0aa6f073890"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
