{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as rd \n",
    "import pickle as pk\n",
    "\n",
    "from Judge.Score import *   # 评价指标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ft = pd.read_csv('./Datasets/train_feature.csv')\n",
    "df_lb = pd.read_csv('./Datasets/train_label.csv') \n",
    "\n",
    "# df_origin = pd.concat([df_ft_origin, df_lb_origin],axis=1)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据预处理\n",
    "首先进行数据的预处理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # print(df_ft_origin.head())\n",
    "# print(df_ft_origin['feature_0'])\n",
    "# print(type(df_ft_origin['feature_0']))\n",
    "# print(df_ft_origin.mean())\n",
    "# print(df_ft_origin.median())\n",
    "# print(df_ft_origin.var())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5195, 121)\n",
      "(5195, 121)\n"
     ]
    }
   ],
   "source": [
    "from Preprocessing import Tools as M_TOOL\n",
    "from Preprocessing import PCA as M_PCA\n",
    "\n",
    "from itertools import chain as ch\n",
    "\n",
    "\n",
    "df = pd.concat([df_ft, df_lb], axis=1)\n",
    "df.fillna(df.median(), inplace=True)\n",
    "\n",
    "# 删除噪声\n",
    "df = M_TOOL.Drop_noise(df, if_debug=False)\n",
    "\n",
    "# 数据归一化\n",
    "# df = M_TOOL.Normalization(df, if_debug=False)\n",
    "\n",
    "\n",
    "# PCA_model = M_PCA.PCA(df.values)\n",
    "# df = pd.DataFrame(PCA_model.reduce_dimension())\n",
    "# print(df.head())\n",
    "# corr = np.array(df.corr())\n",
    "# print(df.corr())\n",
    "\n",
    "\n",
    "# def flat(nest,cond_func=lambda r:type(r)==ast.Num,get_func=lambda r:r.n):\n",
    "#     cd = json.dumps(nest)\n",
    "#     t = ast.parse(cd)\n",
    "#     g = ast.walk(t)\n",
    "#     arr = list(g)\n",
    "#     arr = list(filter(cond_func,arr))\n",
    "#     arr = list(map(get_func,arr))\n",
    "#     return(arr)\n",
    "\n",
    "# 作者：navegador\n",
    "# 链接：https://www.zhihu.com/question/356442472/answer/1585424932\n",
    "# 来源：知乎\n",
    "# 著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。\n",
    "\n",
    "\n",
    "\n",
    "# corr_list = list(ch.from_iterable(corr))\n",
    "\n",
    "# corr_list = list(set(corr_list).difference(set([corr_list[i] for i in range(len(corr_list)-1,-1,-1) if corr_list[i] == 1.0])))\n",
    "\n",
    "# corr_list.sort()\n",
    "# # print(corr_list)\n",
    "\n",
    "# max_list = corr_list[-5:]\n",
    "# print(max_list)\n",
    "\n",
    "\n",
    "    \n",
    "# sub_df_1 = df[df['label'] == 0]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# df.drop_duplicates(inplace=True)\n",
    "# print(df.shape)\n",
    "# print(sub_df_1.head())\n",
    "# print(sub_df_1.corr())\n",
    "\n",
    "print(df.shape)\n",
    "# M_TOOL.Find_useless_feature(df)\n",
    "# df = M_TOOL.Delete_feature(df)\n",
    "print(df.shape)\n",
    "X_train, y_train, X_test, y_test = M_TOOL.random_Split_data(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.manifold import *\n",
    "\n",
    "# m = LocallyLinearEmbedding(n_components=80)\n",
    "# m.fit(X_train, y_train)\n",
    "# X_train = m.transform(X_train)\n",
    "# X_test = m.transform(X_test)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型训练与预测\n",
    "\n",
    "接下来，我们将分别使用线性回归模型、决策树模型、神经网络模型、支持向量机以及 XGBoost 等分类模型对数据集进行训练，并在验证集上进行预测。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "\n",
    "#递归特征消除法，返回特征选择后的数据\n",
    "#参数estimator为基模型\n",
    "#参数n_features_to_select为选择的特征个数\n",
    "# print(X_train.shape)\n",
    "# X_new = RFE(estimator=LinearRegression(), n_features_to_select=50).fit_transform(X_train, y_train)\n",
    "# print(X_new.shape)\n",
    "# drop_index = M_TOOL.Find_drop_feature(X_train, X_new)\n",
    "# # print(drop_index)\n",
    "\n",
    "# X_train = np.delete(X_train, drop_index, axis=1)\n",
    "# X_test = np.delete(X_test, drop_index, axis=1)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "线性回归模型分类准确度为 0.233256351039261\n",
      "SKLearn 分类准确度为 0.23941493456505003\n"
     ]
    }
   ],
   "source": [
    "from Methods import LinearReg as M_LR\n",
    "# 线性回归模型\n",
    "\n",
    "model_liner = M_LR.LinearRegression(X_train, y_train)\n",
    "model_liner.fit()\n",
    "# model_liner.save()\n",
    "# model_liner = pk.load(open(\"./model/Model_LinearReg_2022_12_24_21_07_58.dat\", \"rb\"))    # 使用已保存的模型\n",
    "\n",
    "pre = model_liner.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "acc = Accuracy(pre, y_test)\n",
    "print(\"线性回归模型分类准确度为 {}\".format(acc))\n",
    "\n",
    "\n",
    "# 与 Sklearn 比较\n",
    "from sklearn.linear_model import LinearRegression as LR  \n",
    "model_liner_skl = LR().fit(X_train, y_train)\n",
    "pre_skl = model_liner_skl.predict(X_test)\n",
    "\n",
    "acc = Accuracy(pre_skl, y_test)\n",
    "print(\"SKLearn 分类准确度为 {}\".format(acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|--- feature_37 <= 152.50\n",
      "|   |--- feature_15 <= 13.50\n",
      "|   |   |--- feature_45 <= 6.77\n",
      "|   |   |   |--- feature_9 <= 3.93\n",
      "|   |   |   |   |--- feature_51 <= 0.30\n",
      "|   |   |   |   |   |--- feature_55 <= 60.50\n",
      "|   |   |   |   |   |   |--- feature_10 <= 3.50\n",
      "|   |   |   |   |   |   |   |--- feature_5 <= 185.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |--- feature_5 >  185.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 3\n",
      "|   |   |   |   |   |   |--- feature_10 >  3.50\n",
      "|   |   |   |   |   |   |   |--- class: 3\n",
      "|   |   |   |   |   |--- feature_55 >  60.50\n",
      "|   |   |   |   |   |   |--- class: 2\n",
      "|   |   |   |   |--- feature_51 >  0.30\n",
      "|   |   |   |   |   |--- feature_76 <= 1.50\n",
      "|   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |--- feature_76 >  1.50\n",
      "|   |   |   |   |   |   |--- feature_53 <= 0.23\n",
      "|   |   |   |   |   |   |   |--- feature_49 <= 6.59\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |--- feature_49 >  6.59\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |--- feature_53 >  0.23\n",
      "|   |   |   |   |   |   |   |--- feature_61 <= 25.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 3\n",
      "|   |   |   |   |   |   |   |--- feature_61 >  25.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 2\n",
      "|   |   |   |--- feature_9 >  3.93\n",
      "|   |   |   |   |--- feature_77 <= 0.39\n",
      "|   |   |   |   |   |--- feature_5 <= 241.00\n",
      "|   |   |   |   |   |   |--- feature_86 <= 1.11\n",
      "|   |   |   |   |   |   |   |--- feature_107 <= 31.95\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |--- feature_107 >  31.95\n",
      "|   |   |   |   |   |   |   |   |--- class: 2\n",
      "|   |   |   |   |   |   |--- feature_86 >  1.11\n",
      "|   |   |   |   |   |   |   |--- feature_29 <= 1.35\n",
      "|   |   |   |   |   |   |   |   |--- class: 3\n",
      "|   |   |   |   |   |   |   |--- feature_29 >  1.35\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |--- feature_5 >  241.00\n",
      "|   |   |   |   |   |   |--- feature_22 <= 2.50\n",
      "|   |   |   |   |   |   |   |--- class: 2\n",
      "|   |   |   |   |   |   |--- feature_22 >  2.50\n",
      "|   |   |   |   |   |   |   |--- class: 3\n",
      "|   |   |   |   |--- feature_77 >  0.39\n",
      "|   |   |   |   |   |--- feature_60 <= 9.55\n",
      "|   |   |   |   |   |   |--- feature_17 <= 4.78\n",
      "|   |   |   |   |   |   |   |--- feature_49 <= 2.38\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |--- feature_49 >  2.38\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |--- feature_17 >  4.78\n",
      "|   |   |   |   |   |   |   |--- feature_56 <= 3.09\n",
      "|   |   |   |   |   |   |   |   |--- class: 2\n",
      "|   |   |   |   |   |   |   |--- feature_56 >  3.09\n",
      "|   |   |   |   |   |   |   |   |--- class: 2\n",
      "|   |   |   |   |   |--- feature_60 >  9.55\n",
      "|   |   |   |   |   |   |--- feature_35 <= 1.63\n",
      "|   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |--- feature_35 >  1.63\n",
      "|   |   |   |   |   |   |   |--- feature_117 <= 0.13\n",
      "|   |   |   |   |   |   |   |   |--- class: 2\n",
      "|   |   |   |   |   |   |   |--- feature_117 >  0.13\n",
      "|   |   |   |   |   |   |   |   |--- class: 3\n",
      "|   |   |--- feature_45 >  6.77\n",
      "|   |   |   |--- feature_101 <= 7.43\n",
      "|   |   |   |   |--- feature_44 <= 18.50\n",
      "|   |   |   |   |   |--- feature_11 <= -3.20\n",
      "|   |   |   |   |   |   |--- feature_93 <= 1.50\n",
      "|   |   |   |   |   |   |   |--- class: 3\n",
      "|   |   |   |   |   |   |--- feature_93 >  1.50\n",
      "|   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |--- feature_11 >  -3.20\n",
      "|   |   |   |   |   |   |--- feature_79 <= 5.50\n",
      "|   |   |   |   |   |   |   |--- feature_2 <= 0.85\n",
      "|   |   |   |   |   |   |   |   |--- class: 2\n",
      "|   |   |   |   |   |   |   |--- feature_2 >  0.85\n",
      "|   |   |   |   |   |   |   |   |--- class: 2\n",
      "|   |   |   |   |   |   |--- feature_79 >  5.50\n",
      "|   |   |   |   |   |   |   |--- class: 3\n",
      "|   |   |   |   |--- feature_44 >  18.50\n",
      "|   |   |   |   |   |--- class: 3\n",
      "|   |   |   |--- feature_101 >  7.43\n",
      "|   |   |   |   |--- feature_15 <= 6.50\n",
      "|   |   |   |   |   |--- class: 3\n",
      "|   |   |   |   |--- feature_15 >  6.50\n",
      "|   |   |   |   |   |--- class: 0\n",
      "|   |--- feature_15 >  13.50\n",
      "|   |   |--- feature_64 <= 1.41\n",
      "|   |   |   |--- feature_101 <= 3.41\n",
      "|   |   |   |   |--- feature_15 <= 21.50\n",
      "|   |   |   |   |   |--- feature_104 <= 0.33\n",
      "|   |   |   |   |   |   |--- feature_17 <= 1.17\n",
      "|   |   |   |   |   |   |   |--- feature_26 <= 2.19\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |--- feature_26 >  2.19\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |--- feature_17 >  1.17\n",
      "|   |   |   |   |   |   |   |--- feature_97 <= 46.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |--- feature_97 >  46.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 2\n",
      "|   |   |   |   |   |--- feature_104 >  0.33\n",
      "|   |   |   |   |   |   |--- feature_26 <= 1.86\n",
      "|   |   |   |   |   |   |   |--- feature_16 <= 0.69\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |--- feature_16 >  0.69\n",
      "|   |   |   |   |   |   |   |   |--- class: 3\n",
      "|   |   |   |   |   |   |--- feature_26 >  1.86\n",
      "|   |   |   |   |   |   |   |--- feature_33 <= 0.76\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |--- feature_33 >  0.76\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |--- feature_15 >  21.50\n",
      "|   |   |   |   |   |--- feature_40 <= 11.80\n",
      "|   |   |   |   |   |   |--- feature_48 <= 0.48\n",
      "|   |   |   |   |   |   |   |--- feature_111 <= 0.15\n",
      "|   |   |   |   |   |   |   |   |--- class: 2\n",
      "|   |   |   |   |   |   |   |--- feature_111 >  0.15\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |--- feature_48 >  0.48\n",
      "|   |   |   |   |   |   |   |--- feature_2 <= 0.56\n",
      "|   |   |   |   |   |   |   |   |--- class: 2\n",
      "|   |   |   |   |   |   |   |--- feature_2 >  0.56\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |--- feature_40 >  11.80\n",
      "|   |   |   |   |   |   |--- feature_85 <= 0.25\n",
      "|   |   |   |   |   |   |   |--- feature_62 <= 3.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |--- feature_62 >  3.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |--- feature_85 >  0.25\n",
      "|   |   |   |   |   |   |   |--- feature_40 <= 15.25\n",
      "|   |   |   |   |   |   |   |   |--- class: 2\n",
      "|   |   |   |   |   |   |   |--- feature_40 >  15.25\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |--- feature_101 >  3.41\n",
      "|   |   |   |   |--- feature_106 <= 9.50\n",
      "|   |   |   |   |   |--- feature_64 <= 0.08\n",
      "|   |   |   |   |   |   |--- feature_45 <= -4.44\n",
      "|   |   |   |   |   |   |   |--- class: 2\n",
      "|   |   |   |   |   |   |--- feature_45 >  -4.44\n",
      "|   |   |   |   |   |   |   |--- feature_95 <= 2.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |--- feature_95 >  2.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 3\n",
      "|   |   |   |   |   |--- feature_64 >  0.08\n",
      "|   |   |   |   |   |   |--- feature_108 <= 7.35\n",
      "|   |   |   |   |   |   |   |--- feature_28 <= 16.05\n",
      "|   |   |   |   |   |   |   |   |--- class: 3\n",
      "|   |   |   |   |   |   |   |--- feature_28 >  16.05\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |--- feature_108 >  7.35\n",
      "|   |   |   |   |   |   |   |--- feature_31 <= 0.35\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |--- feature_31 >  0.35\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |--- feature_106 >  9.50\n",
      "|   |   |   |   |   |--- feature_17 <= 2.15\n",
      "|   |   |   |   |   |   |--- class: 2\n",
      "|   |   |   |   |   |--- feature_17 >  2.15\n",
      "|   |   |   |   |   |   |--- class: 0\n",
      "|   |   |--- feature_64 >  1.41\n",
      "|   |   |   |--- feature_83 <= 9.50\n",
      "|   |   |   |   |--- feature_53 <= 7.45\n",
      "|   |   |   |   |   |--- feature_97 <= 66.50\n",
      "|   |   |   |   |   |   |--- feature_25 <= 8.50\n",
      "|   |   |   |   |   |   |   |--- feature_20 <= 0.32\n",
      "|   |   |   |   |   |   |   |   |--- class: 3\n",
      "|   |   |   |   |   |   |   |--- feature_20 >  0.32\n",
      "|   |   |   |   |   |   |   |   |--- class: 2\n",
      "|   |   |   |   |   |   |--- feature_25 >  8.50\n",
      "|   |   |   |   |   |   |   |--- feature_75 <= 12.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |--- feature_75 >  12.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 3\n",
      "|   |   |   |   |   |--- feature_97 >  66.50\n",
      "|   |   |   |   |   |   |--- feature_67 <= 2.01\n",
      "|   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |--- feature_67 >  2.01\n",
      "|   |   |   |   |   |   |   |--- class: 3\n",
      "|   |   |   |   |--- feature_53 >  7.45\n",
      "|   |   |   |   |   |--- feature_93 <= 2.50\n",
      "|   |   |   |   |   |   |--- feature_110 <= 3.50\n",
      "|   |   |   |   |   |   |   |--- feature_0 <= 53.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 3\n",
      "|   |   |   |   |   |   |   |--- feature_0 >  53.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 2\n",
      "|   |   |   |   |   |   |--- feature_110 >  3.50\n",
      "|   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |--- feature_93 >  2.50\n",
      "|   |   |   |   |   |   |--- feature_81 <= 43.50\n",
      "|   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |--- feature_81 >  43.50\n",
      "|   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |--- feature_83 >  9.50\n",
      "|   |   |   |   |--- feature_81 <= 52.50\n",
      "|   |   |   |   |   |--- feature_60 <= 1.13\n",
      "|   |   |   |   |   |   |--- feature_74 <= 0.78\n",
      "|   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |--- feature_74 >  0.78\n",
      "|   |   |   |   |   |   |   |--- feature_37 <= 132.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |--- feature_37 >  132.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |--- feature_60 >  1.13\n",
      "|   |   |   |   |   |   |--- feature_64 <= 5.35\n",
      "|   |   |   |   |   |   |   |--- feature_23 <= 1.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |--- feature_23 >  1.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 2\n",
      "|   |   |   |   |   |   |--- feature_64 >  5.35\n",
      "|   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |--- feature_81 >  52.50\n",
      "|   |   |   |   |   |--- feature_66 <= 1.17\n",
      "|   |   |   |   |   |   |--- feature_11 <= 1.42\n",
      "|   |   |   |   |   |   |   |--- class: 3\n",
      "|   |   |   |   |   |   |--- feature_11 >  1.42\n",
      "|   |   |   |   |   |   |   |--- class: 3\n",
      "|   |   |   |   |   |--- feature_66 >  1.17\n",
      "|   |   |   |   |   |   |--- feature_9 <= 6.64\n",
      "|   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |--- feature_9 >  6.64\n",
      "|   |   |   |   |   |   |   |--- class: 0\n",
      "|--- feature_37 >  152.50\n",
      "|   |--- feature_109 <= 47.50\n",
      "|   |   |--- feature_5 <= 128.50\n",
      "|   |   |   |--- feature_50 <= 69.20\n",
      "|   |   |   |   |--- class: 0\n",
      "|   |   |   |--- feature_50 >  69.20\n",
      "|   |   |   |   |--- class: 0\n",
      "|   |   |--- feature_5 >  128.50\n",
      "|   |   |   |--- feature_55 <= 16.50\n",
      "|   |   |   |   |--- feature_112 <= 51.50\n",
      "|   |   |   |   |   |--- feature_46 <= 0.87\n",
      "|   |   |   |   |   |   |--- feature_32 <= 0.47\n",
      "|   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |--- feature_32 >  0.47\n",
      "|   |   |   |   |   |   |   |--- class: 2\n",
      "|   |   |   |   |   |--- feature_46 >  0.87\n",
      "|   |   |   |   |   |   |--- feature_20 <= 0.43\n",
      "|   |   |   |   |   |   |   |--- class: 3\n",
      "|   |   |   |   |   |   |--- feature_20 >  0.43\n",
      "|   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |--- feature_112 >  51.50\n",
      "|   |   |   |   |   |--- feature_64 <= 1.46\n",
      "|   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |--- feature_64 >  1.46\n",
      "|   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |--- feature_55 >  16.50\n",
      "|   |   |   |   |--- feature_113 <= 0.05\n",
      "|   |   |   |   |   |--- class: 3\n",
      "|   |   |   |   |--- feature_113 >  0.05\n",
      "|   |   |   |   |   |--- feature_58 <= 5.07\n",
      "|   |   |   |   |   |   |--- feature_80 <= 5.98\n",
      "|   |   |   |   |   |   |   |--- feature_5 <= 234.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |--- feature_5 >  234.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |--- feature_80 >  5.98\n",
      "|   |   |   |   |   |   |   |--- feature_64 <= 1.40\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |--- feature_64 >  1.40\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |--- feature_58 >  5.07\n",
      "|   |   |   |   |   |   |--- class: 2\n",
      "|   |--- feature_109 >  47.50\n",
      "|   |   |--- feature_53 <= 0.06\n",
      "|   |   |   |--- class: 1\n",
      "|   |   |--- feature_53 >  0.06\n",
      "|   |   |   |--- feature_49 <= 6.56\n",
      "|   |   |   |   |--- feature_76 <= 8.50\n",
      "|   |   |   |   |   |--- feature_75 <= 10.50\n",
      "|   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |--- feature_75 >  10.50\n",
      "|   |   |   |   |   |   |--- feature_67 <= 2.00\n",
      "|   |   |   |   |   |   |   |--- feature_5 <= 188.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |--- feature_5 >  188.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |--- feature_67 >  2.00\n",
      "|   |   |   |   |   |   |   |--- feature_2 <= 0.44\n",
      "|   |   |   |   |   |   |   |   |--- class: 2\n",
      "|   |   |   |   |   |   |   |--- feature_2 >  0.44\n",
      "|   |   |   |   |   |   |   |   |--- class: 3\n",
      "|   |   |   |   |--- feature_76 >  8.50\n",
      "|   |   |   |   |   |--- feature_98 <= 1.50\n",
      "|   |   |   |   |   |   |--- feature_33 <= 2.20\n",
      "|   |   |   |   |   |   |   |--- feature_81 <= 61.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |--- feature_81 >  61.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 2\n",
      "|   |   |   |   |   |   |--- feature_33 >  2.20\n",
      "|   |   |   |   |   |   |   |--- feature_118 <= 1.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 2\n",
      "|   |   |   |   |   |   |   |--- feature_118 >  1.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |--- feature_98 >  1.50\n",
      "|   |   |   |   |   |   |--- feature_91 <= 0.64\n",
      "|   |   |   |   |   |   |   |--- feature_107 <= 18.80\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |--- feature_107 >  18.80\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |--- feature_91 >  0.64\n",
      "|   |   |   |   |   |   |   |--- feature_78 <= 2.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 3\n",
      "|   |   |   |   |   |   |   |--- feature_78 >  2.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 2\n",
      "|   |   |   |--- feature_49 >  6.56\n",
      "|   |   |   |   |--- feature_15 <= 61.00\n",
      "|   |   |   |   |   |--- feature_43 <= 1.24\n",
      "|   |   |   |   |   |   |--- class: 2\n",
      "|   |   |   |   |   |--- feature_43 >  1.24\n",
      "|   |   |   |   |   |   |--- feature_56 <= 1.49\n",
      "|   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |--- feature_56 >  1.49\n",
      "|   |   |   |   |   |   |   |--- class: 3\n",
      "|   |   |   |   |--- feature_15 >  61.00\n",
      "|   |   |   |   |   |--- class: 1\n",
      "\n",
      "决策树分类准确度为 0.26250962278675904\n"
     ]
    }
   ],
   "source": [
    "# 决策树模型\n",
    "\n",
    "from Methods import DecTree as M_DTC\n",
    "parameters = {\n",
    "    \"criterion\": \"gini\",       # 选择特征的标准，分为 \"gini\" 和 \"entropy\"\n",
    "    \"splitter\": \"best\",        # 特征划分标准，分为 \"best\" 和 \"random\"\n",
    "    \"max_depth\": 8,\n",
    "    \"min_samples_split\": 7,   \n",
    "    \"min_samples_leaf\": 4,    \n",
    "    \"max_leaf_nodes\": 1000,   \n",
    "    \"min_impurity_decrease\": 0.0, \n",
    "    \"if_silent\": 1\n",
    "}\n",
    "\n",
    "model_dtc = M_DTC.DecisionTree(X_train, y_train)\n",
    "model_dtc.fit(parameters)\n",
    "\n",
    "pre = model_dtc.predict(X_test)\n",
    "pre = np.array(pre).reshape(-1, 1)\n",
    "\n",
    "\n",
    "acc_dtc = Accuracy(pre, y_test)\n",
    "print(\"决策树分类准确度为 {}\".format(acc_dtc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters = {\n",
    "#     \"criterion\": \"gini\",    # 选择特征的标准，分为 \"gini\" 和 \"entropy\"\n",
    "#     \"splitter\": \"best\",        # 特征划分标准，分为 \"best\" 和 \"random\"\n",
    "#     \"max_depth\": 14,\n",
    "#     \"min_samples_split\": 2,    # 叶子最小样本数\n",
    "#     \"min_samples_leaf\": 4,     # 划分最小样本数\n",
    "#     \"max_leaf_nodes\": 10000,    # 最大叶节点个数\n",
    "#     \"min_impurity_decrease\": 0.0, # 最小划分不纯度减少量\n",
    "#     \"if_silent\": 1\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from Methods import RegTree as M_RT\n",
    "# # 回归树模型\n",
    "\n",
    "# m, n = y_train.shape \n",
    "# y_t = np.zeros((m, n))\n",
    "# model_regtree = M_RT.RegressionTree(X_train, y_train, y_t)\n",
    "# default_parameters = {\n",
    "#     \"lamda\": 2,             # Hyperparameters\n",
    "#     \"gamma\": 1e-6,          # Hyperparameters\n",
    "#     \"gain_delta\": 0,        # The minimum gain\n",
    "#     \"max_depth\": 3,\n",
    "#     \"max_leaves\": 100,\n",
    "#     \"max_nodes\": 1000,\n",
    "#     \"min_samples\": 10,      # Minimum number of samples on a leaf\n",
    "#     \"min_feature_dif\": 5,   # The minimum number of different value for current feature\n",
    "#     \"if_silent\": 0\n",
    "# }\n",
    "# model_regtree.fit(default_parameters)\n",
    "# pre = model_regtree.predict(X_test)\n",
    "\n",
    "# acc = Accuracy(pre, Y_test)\n",
    "# print(\"回归树模型分类准确度为 {}\".format(acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from Methods import SVM as M_SVM\n",
    "# # 支持向量机模型\n",
    "\n",
    "# model_SVM = M_SVM.SupportVectorMachine(X_train, y_train)\n",
    "# model_SVM.fit(max_times=500, ifsilent=True)\n",
    "# pre = model_SVM.predict(X_test)\n",
    "\n",
    "# acc = Accuracy(pre, Y_test)\n",
    "# print(\"SVM 模型分类准确度为 {}\".format(acc))\n",
    "\n",
    "\n",
    "# # 与 SKLearn 比较\n",
    "# from sklearn import svm \n",
    "# model = svm.SVC(kernel='linear')\n",
    "# model.fit(X_train, y_train.flatten())\n",
    "# pre_skl = model.predict(X_test).reshape(-1, 1)\n",
    "\n",
    "# acc = Accuracy(pre_skl, Y_test)\n",
    "# print(\"SKLearn 分类准确度为 {}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from Methods import NeuralNet as M_NN\n",
    "# # 神经网络模型\n",
    "\n",
    "# model_NN = M_NN.NeuralNetwork(X_train, y_train.flatten())\n",
    "# model_NN.fit()\n",
    "# pre = model_liner.predict(X_test)\n",
    "\n",
    "# acc_1 = Accuracy(pre, Y_test)\n",
    "# print(\"线性回归模型分类准确度为 {}\".format(acc_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create model. feature_dim =120, label_dim =1\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_3 (Dense)             (None, 500)               60500     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 100)               50100     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 110,701\n",
      "Trainable params: 110,701\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/15\n",
      "244/244 [==============================] - 1s 2ms/step - loss: -4893.6455 - accuracy: 0.2539 - val_loss: -21779.7891 - val_accuracy: 0.2371\n",
      "Epoch 2/15\n",
      "244/244 [==============================] - 0s 1ms/step - loss: -88281.3906 - accuracy: 0.2539 - val_loss: -205683.0938 - val_accuracy: 0.2371\n",
      "Epoch 3/15\n",
      "244/244 [==============================] - 0s 1ms/step - loss: -407316.1250 - accuracy: 0.2539 - val_loss: -708567.0625 - val_accuracy: 0.2371\n",
      "Epoch 4/15\n",
      "244/244 [==============================] - 0s 1ms/step - loss: -1091679.5000 - accuracy: 0.2539 - val_loss: -1642853.0000 - val_accuracy: 0.2371\n",
      "Epoch 5/15\n",
      "244/244 [==============================] - 0s 1ms/step - loss: -2240341.7500 - accuracy: 0.2539 - val_loss: -3096136.2500 - val_accuracy: 0.2371\n",
      "Epoch 6/15\n",
      "244/244 [==============================] - 0s 1ms/step - loss: -3897407.0000 - accuracy: 0.2539 - val_loss: -5100030.5000 - val_accuracy: 0.2371\n",
      "Epoch 7/15\n",
      "244/244 [==============================] - 0s 1ms/step - loss: -6120847.0000 - accuracy: 0.2539 - val_loss: -7746936.0000 - val_accuracy: 0.2371\n",
      "Epoch 8/15\n",
      "244/244 [==============================] - 0s 1ms/step - loss: -8959301.0000 - accuracy: 0.2539 - val_loss: -11021781.0000 - val_accuracy: 0.2371\n",
      "Epoch 9/15\n",
      "244/244 [==============================] - 0s 1ms/step - loss: -12472582.0000 - accuracy: 0.2539 - val_loss: -15025318.0000 - val_accuracy: 0.2371\n",
      "Epoch 10/15\n",
      "244/244 [==============================] - 0s 1ms/step - loss: -16710200.0000 - accuracy: 0.2539 - val_loss: -19828418.0000 - val_accuracy: 0.2371\n",
      "Epoch 11/15\n",
      "244/244 [==============================] - 0s 1ms/step - loss: -21669036.0000 - accuracy: 0.2539 - val_loss: -25367396.0000 - val_accuracy: 0.2371\n",
      "Epoch 12/15\n",
      "244/244 [==============================] - 0s 1ms/step - loss: -27325946.0000 - accuracy: 0.2539 - val_loss: -31644504.0000 - val_accuracy: 0.2371\n",
      "Epoch 13/15\n",
      "244/244 [==============================] - 0s 1ms/step - loss: -33695936.0000 - accuracy: 0.2539 - val_loss: -38602668.0000 - val_accuracy: 0.2371\n",
      "Epoch 14/15\n",
      "244/244 [==============================] - 0s 1ms/step - loss: -40887920.0000 - accuracy: 0.2539 - val_loss: -46569064.0000 - val_accuracy: 0.2371\n",
      "Epoch 15/15\n",
      "244/244 [==============================] - 0s 1ms/step - loss: -48936236.0000 - accuracy: 0.2539 - val_loss: -55390288.0000 - val_accuracy: 0.2371\n"
     ]
    }
   ],
   "source": [
    "def deep_model(feature_dim,label_dim):\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import Dense\n",
    "    model = Sequential()\n",
    "    print(\"create model. feature_dim ={}, label_dim ={}\".format(feature_dim, label_dim))\n",
    "    model.add(Dense(500, activation='relu', input_dim=feature_dim))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(label_dim, activation='sigmoid'))\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_deep(X_train,y_train,X_test,y_test):\n",
    "    feature_dim = 120\n",
    "    label_dim = 1\n",
    "    model = deep_model(feature_dim,label_dim)\n",
    "    model.summary()\n",
    "    model.fit(X_train,y_train,batch_size=16, epochs=15,validation_data=(X_test,y_test))\n",
    "    \n",
    "train_deep(X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from Methods import XGBoost as M_XGB\n",
    "# # XGBoost 模型\n",
    "\n",
    "# model_XGB = M_XGB.XGBoost(X_train, y_train)\n",
    "\n",
    "# model_XGB.fit(T=100, max_depth=8)\n",
    "# pre = model_XGB.predict(X_test)\n",
    "# pre = np.array(pre).reshape(-1, 1)\n",
    "\n",
    "# acc_xgb = Accuracy(pre, y_test)\n",
    "# print(\"XGBoost 模型分类准确度为 {}\".format(acc_xgb))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2469a70536e4d2335a2ea8907942d0699c37342a371ac185bdb5b0aa6f073890"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
