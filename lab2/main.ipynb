{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate data\n",
    "\n",
    "This section is provided by the TAs. The function can randomly generate a dataset of a specified size and provide the original misscaling rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(dim=10, num=100, random_seed=-1):\n",
    "    \n",
    "    if random_seed != -1:\n",
    "        np.random.seed(random_seed)\n",
    "    x = np.random.normal(0, 10, [num, dim])\n",
    "\n",
    "    if random_seed != -1:\n",
    "        np.random.seed(random_seed)\n",
    "    coef = np.random.uniform(-1, 1, [dim, 1])\n",
    "\n",
    "    pred = np.dot(x, coef)\n",
    "    pred_n = (pred - np.mean(pred)) / np.sqrt(np.var(pred))\n",
    "    label = np.sign(pred_n)\n",
    "\n",
    "    if random_seed != -1:\n",
    "        np.random.seed(random_seed)\n",
    "    mislabel_value = np.random.uniform(0, 1, num)\n",
    "    mislabel = 0\n",
    "\n",
    "    for i in range(num):\n",
    "        if np.abs(pred_n[i]) < 1 and mislabel_value[i] > 0.9 + 0.1 * np.abs(pred_n[i]):\n",
    "            label[i] *= -1\n",
    "            mislabel += 1\n",
    "    return x, label, mislabel/num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1: Gradient descent\n",
    "\n",
    "This model solves the soft interval support vector machine based on gradient descent. The derivation of the formula has been listed in the experimental report. Here is the code implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1: Gradient descent\n",
    "\n",
    "def my_max(a, b):\n",
    "    return a if a > b else b\n",
    "\n",
    "def find_zero(a, b):\n",
    "    return 0 if a == 0 else b\n",
    "\n",
    "def array_max(a:np.ndarray, b:np.ndarray)->np.ndarray:\n",
    "    func_ = np.frompyfunc(my_max, 2, 1)\n",
    "    return(func_(a, b))\n",
    "\n",
    "def array_find0(a:np.ndarray, b:np.ndarray) -> np.ndarray:\n",
    "    func_ = np.frompyfunc(find_zero, 2, 1)\n",
    "    return(func_(a, b))\n",
    "\n",
    "# The above function implements the corresponding operation of each dimension of the vector.\n",
    "\n",
    "class SVM1:\n",
    "    def __init__(self, X:np.ndarray, y:np.ndarray):\n",
    "        \"\"\"\n",
    "        ---\n",
    "        Args:\n",
    "        ---\n",
    "            X (np.ndarray): \n",
    "                Data characteristics\n",
    "            y (np.ndarray): \n",
    "                Data category\n",
    "        \"\"\"\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.m, self.n = self.X.shape \n",
    "        self.w = np.zeros((self.n + 1, 1))\n",
    "\n",
    "    def fit(self, gamma=0.25, lr=0.002, tol=1e-4, max_times=500, ifsilent=True):\n",
    "        \"\"\"\n",
    "        ---\n",
    "        Args:\n",
    "        ---\n",
    "            gamma: \n",
    "                Regularization parameters. \n",
    "                By default 0.25\n",
    "            lr: \n",
    "                Learning rate. \n",
    "                By default 0.002\n",
    "            max_times: \n",
    "                The maximum times of training iterations. \n",
    "                By default 500\n",
    "            tol: \n",
    "                The minimum amount of change for the adjacent two iterations of the loss function.\n",
    "                By default 1e-4\n",
    "            ifsilent: \n",
    "                Whether toprint training process information. \n",
    "                If False, the program will print the value of the loss function during iteration. \n",
    "                By default True\n",
    "        \"\"\"\n",
    "\n",
    "        # Preprocess the training data\n",
    "        temp_1 = np.ones((self.m, 1))\n",
    "        X_hat:np.ndarray = np.c_[self.X, temp_1]\n",
    "\n",
    "        temp_0 = np.zeros((self.m, 1))\n",
    "        loss_list = []\n",
    "        y_diag = np.diag(self.y.reshape(-1))\n",
    "        \n",
    "        info_gap = max_times / 20\n",
    "        \n",
    "        # Start iterating\n",
    "        if ifsilent:\n",
    "            for times in range(max_times):\n",
    "                xi = array_max(temp_0, 1 - (y_diag @ X_hat @ self.w))\n",
    "                loss = 0.5 * (self.w.T @ self.w)[0][0] + gamma * (xi.sum())\n",
    "            \n",
    "                y_bar = array_find0(xi , self.y)\n",
    "                delta_1 = self.w - gamma * (X_hat.T @ y_bar)\n",
    "                \n",
    "                if times >= 2 and abs(loss_list[-1] - loss) < tol:\n",
    "                    loss_list.append(loss)\n",
    "                    break\n",
    "\n",
    "                self.w = self.w - lr * delta_1\n",
    "                loss_list.append(loss)\n",
    "        else:\n",
    "            for times in range(max_times):\n",
    "                xi = array_max(temp_0, 1 - (y_diag @ X_hat @ self.w))\n",
    "                loss = 0.5 * (self.w.T @ self.w)[0][0] + gamma * (xi.sum())\n",
    "                \n",
    "                y_bar = array_find0(xi , self.y)\n",
    "                delta_1 = self.w - gamma * (X_hat.T @ y_bar)\n",
    "                \n",
    "                if times >= 2 and abs(loss_list[-1] - loss) < tol:\n",
    "                    loss_list.append(loss)\n",
    "                    break\n",
    "\n",
    "                if (times % info_gap == 0):\n",
    "                    print(\"Current times: {}, loss is {}\".format(times, loss))\n",
    "\n",
    "                self.w = self.w - lr * delta_1\n",
    "                loss_list.append(loss)\n",
    "\n",
    "        return loss_list, times\n",
    "            \n",
    "\n",
    "        \n",
    "    def predict(self, X:np.ndarray) -> np.ndarray:\n",
    "        m, n = X.shape\n",
    "        temp_1 = np.ones(m)\n",
    "        X_hat:np.ndarray = np.c_[X, temp_1]\n",
    "        temp = X_hat @ self.w\n",
    "        ans = []\n",
    "        for i in range(m):\n",
    "            if temp[i] > 0:\n",
    "                ans.append(1)\n",
    "            else:\n",
    "                ans.append(-1)\n",
    "        return np.array(ans).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2: Sequential Minimal Optimization\n",
    "\n",
    "This model solves the soft interval support vector machine based on SMO. The derivation of the formula has been listed in the experimental report. Here is the code implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def takefirst(elm:(float | int)) -> float:\n",
    "    # This function is only used when sorting.\n",
    "    return elm[0]\n",
    "\n",
    "\n",
    "class SVM2:\n",
    "    def __init__(self, X:np.ndarray, y:np.ndarray):\n",
    "        \"\"\"\n",
    "        ---\n",
    "        Args:\n",
    "        ---\n",
    "            X (np.ndarray): \n",
    "                Data characteristics \n",
    "            y (np.ndarray): \n",
    "                Data category\n",
    "        \"\"\"\n",
    "        m, _ = X.shape\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.K = self.X @ self.X.T\n",
    "        \n",
    "        self.alpha = np.zeros((m, 1))\n",
    "        self.b = np.random.uniform(low=0.0, high=1.0, size=1)\n",
    "        self.err = np.zeros((m, 1))\n",
    "        self._update_e()\n",
    "\n",
    "       \n",
    "\n",
    "    def _cut(self, low, high, a2_uncut):\n",
    "        if a2_uncut > high:\n",
    "            return high\n",
    "        elif a2_uncut < low:\n",
    "            return low\n",
    "        return a2_uncut\n",
    "\n",
    "\n",
    "    def _update_alpha(self, a1_index, a2_index, gamma, min_delta, ifsilent) -> bool:\n",
    "\n",
    "        eta = self.K[a1_index][a1_index] + self.K[a2_index][a2_index] - 2 * self.K[a1_index, a2_index]\n",
    "        alpha1_old = self.alpha[a1_index, :][0]\n",
    "        alpha2_old = self.alpha[a2_index, :][0]\n",
    "        y1 = self.y[a1_index, :][0]\n",
    "        y2 = self.y[a2_index, :][0]\n",
    "        err1 = self.err[a1_index, :][0]\n",
    "        err2 = self.err[a2_index, :][0]\n",
    "\n",
    "        if eta > 0:\n",
    "            a2_uncut = alpha2_old + y2 * (err1 - err2) / eta\n",
    "        else:\n",
    "            if ifsilent == False:\n",
    "                print(\"Eta <= 0\")\n",
    "            return False\n",
    "        \n",
    "        if y1 != y2:\n",
    "            low = max(0, alpha2_old - alpha1_old)\n",
    "            high = min(gamma, gamma + alpha2_old - alpha1_old)\n",
    "        else:\n",
    "            low = max(0, alpha2_old + alpha1_old - gamma)\n",
    "            high = min(gamma, alpha2_old + alpha1_old)\n",
    "\n",
    "        if low > high:\n",
    "            if ifsilent == False:\n",
    "                print(\"Low == High\")\n",
    "            return False\n",
    "\n",
    "        alpha2_new = self._cut(low, high, a2_uncut)\n",
    "        \n",
    "\n",
    "        if (abs(alpha2_old - alpha2_new) < 1e-3):\n",
    "            if ifsilent == False:\n",
    "                print(\"Alpha2 moves too slow\")\n",
    "            return False\n",
    "\n",
    "        alpha1_new = alpha1_old + y1 * y2 * (alpha2_old - alpha2_new)\n",
    "        self._update_b(a1_index, a2_index, alpha1_new, alpha2_new, gamma)\n",
    "\n",
    "        self.alpha[a1_index] = alpha1_new\n",
    "        self.alpha[a2_index] = alpha2_new\n",
    "\n",
    "        self._update_e()\n",
    "\n",
    "        return True\n",
    "\n",
    "\n",
    "    def _update_b(self, a1_index, a2_index, a1_new, a2_new, gamma):\n",
    "        alpha_1 = self.alpha[a1_index, :][0] \n",
    "        alpha_2 = self.alpha[a2_index, :][0] \n",
    "        y1 = self.y[a1_index, :][0]\n",
    "        y2 = self.y[a2_index, :][0]\n",
    "        err1 = self.err[a1_index, :][0]\n",
    "        err2 = self.err[a2_index, :][0]\n",
    "\n",
    "        b1 = -err1 - y1 * self.K[a1_index][a1_index] * (a1_new - alpha_1) - y2 * self.K[a2_index, a1_index] * (a2_new - alpha_2) + self.b\n",
    "        if 0 < alpha_1 < gamma:\n",
    "            self.b = b1\n",
    "            return\n",
    "      \n",
    "        b2 = -err2 - y1 * self.K[a1_index, a2_index] * (a1_new - alpha_1) - y2 * self.K[a2_index][a2_index] * (a2_new - alpha_2) + self.b\n",
    "        if 0 < alpha_2 < gamma:\n",
    "            self.b = b2\n",
    "            return\n",
    "        \n",
    "        self.b = 0.5 * (b1 + b2)\n",
    "        return\n",
    "\n",
    "\n",
    "    def _update_e(self):\n",
    "        alpha_y = self.alpha * self.y\n",
    "        self.err = self.K @ alpha_y + self.b - self.y\n",
    "\n",
    "    def fit(self, gamma=0.05, tol=1e-4, max_times=2000, epslion=0.45, min_delta=1e-3, ifsilent=True):\n",
    "        \"\"\"\n",
    "        ---\n",
    "        Args:\n",
    "        ---\n",
    "            gamma: \n",
    "                Regularization parameters. \n",
    "                By default 0.05\n",
    "            tol: \n",
    "                The minimum amount of change for the adjacent two iterations of the loss function.\n",
    "                By default 1e-4\n",
    "            max_times: \n",
    "                The maximum times of training iterations. \n",
    "                By default 2000\n",
    "            epslion:\n",
    "                Maximum error of samples violating KKT conditions.\n",
    "                Data within the margin of error will NOT be considered a violation of the KKT condition.\n",
    "                By default 0.45\n",
    "            min_delta:\n",
    "                The minimum step size while updating alpha. Updates below this step will be ignored.\n",
    "                By default 1e-3\n",
    "            ifsilent: \n",
    "                Whether toprint training process information. \n",
    "                If False, the program will print the reason for the iteration failure. \n",
    "                By default True\n",
    "        \"\"\"\n",
    "        m, n = self.X.shape\n",
    "\n",
    "        loss_list = []\n",
    "        times = 0\n",
    "        \n",
    "        while times < max_times:\n",
    "            alpha_y = self.alpha * self.y\n",
    "            loss = self.alpha.sum() - 0.5 * (alpha_y.T @ self.X @ self.X.T @ alpha_y)[0][0]\n",
    "\n",
    "            # Calculates the degree to which each alpha violates the KKT condition.\n",
    "            i_list = []\n",
    "            for i in range(m):\n",
    "                alpha_i = self.alpha[i, :][0]\n",
    "                err_i = self.err[i, :][0]\n",
    "                if (0 < alpha_i < gamma and abs(err_i - 1) > epslion):\n",
    "                    val = (abs(err_i) - epslion) * 10\n",
    "                    i_list.append((val, i))\n",
    "                elif alpha_i == 0 and err_i < 1 - epslion:\n",
    "                    val = - err_i + 1 - epslion\n",
    "                    i_list.append((val, i))\n",
    "                elif alpha_i >= gamma and err_i > 1 + epslion:\n",
    "                    val = err_i - 1 - epslion\n",
    "                    i_list.append((val, i))\n",
    "\n",
    "            if times > 2 and len(i_list) == 0:\n",
    "                # No alpha breaks the KKT condition. STOP!\n",
    "                loss_list.append(loss)\n",
    "                break\n",
    "\n",
    "            i_list.sort(key = takefirst)\n",
    "            # Find alpha_i: The alpha with the most severe violation of the KKT condition.\n",
    "\n",
    "            while len(i_list) > 0:\n",
    "                _, a1 = i_list.pop()\n",
    "                e1 = self.err[a1, :][0]\n",
    "\n",
    "                err_dict = []\n",
    "                err_list = []\n",
    "                for i in self.err.tolist():\n",
    "                    err_list.append(i[0])\n",
    "                for index, value in enumerate(err_list):\n",
    "                    err_dict.append((value, index))\n",
    "                err_dict.sort(key = takefirst)\n",
    "\n",
    "                # Find alpha_j: The alpha with the largest difference in error.\n",
    "                k = 0\n",
    "                if e1 > 0:\n",
    "                    while k < m:\n",
    "                        a2 = err_dict[k][1]\n",
    "                        if a1 != a2 and self._update_alpha(a1, a2, gamma, min_delta, ifsilent):\n",
    "                            break\n",
    "                        k += 1\n",
    "                else:\n",
    "                    while k < m:\n",
    "                        a2 = err_dict[-1 - k][1]\n",
    "                        if a1 != a2 and self._update_alpha(a1, a2, gamma, min_delta, ifsilent):\n",
    "                            break\n",
    "                        k += 1\n",
    "\n",
    "                if k == m:\n",
    "                    continue  # Choose next alpha_i\n",
    "                else:\n",
    "                    break\n",
    "\n",
    "            if times >= 2 and abs(loss_list[-1] - loss) < tol:\n",
    "                loss_list.append(loss)\n",
    "                break\n",
    "\n",
    "            loss_list.append(loss)\n",
    "            times += 1\n",
    "\n",
    "        if times == max_times:\n",
    "            times -= 1\n",
    "        return loss_list, times\n",
    "\n",
    "\n",
    "    def predict(self, X:np.ndarray) -> np.ndarray:\n",
    "        m, n = X.shape\n",
    "        ans = []\n",
    "        for i in range(m):\n",
    "            alpha_y = self.alpha * self.y\n",
    "            temp = (alpha_y.T @ self.X @ X[i, :].T)[0] + self.b\n",
    "            if temp > 0:\n",
    "                ans.append(1)\n",
    "            else:\n",
    "                ans.append(-1)      \n",
    "        return np.array(ans).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some useful functions\n",
    "def random_Split_data(X: np.ndarray, y:np.ndarray, rate = 0.7, random_seed: int = -1):\n",
    "    data: np.ndarray = np.hstack((X, y))\n",
    "    m, n = data.shape\n",
    "    if random_seed != -1:\n",
    "        np.random.seed(abs(random_seed))\n",
    "    np.random.shuffle(data)\n",
    "    \n",
    "    row_split = int(m * rate)\n",
    "    X_train = data[0: row_split, 0: -1]\n",
    "    y_train = data[0: row_split, -1: ]\n",
    "    X_test = data[row_split: m, 0: -1]\n",
    "    y_test = data[row_split: m, -1: ]\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "\n",
    "def model_cmp(y_pre:np.ndarray, y_test:np.ndarray):\n",
    "    # y should be in shape m x 1\n",
    "    corr = 0\n",
    "    sum = 0\n",
    "    m, n = y_pre.shape\n",
    "    for i in range(m):\n",
    "        if y_pre[i] == y_test[i]:\n",
    "            corr += 1\n",
    "        sum += 1\n",
    "    return corr/sum\n",
    "\n",
    "\n",
    "def show(times, loss, color = '#4169E1', start=0, end=2000):\n",
    "    x_axis_data = list(range(times + 1))[start:end]\n",
    "    y_axis_data = loss[start:end]\n",
    "    plt.plot(x_axis_data, y_axis_data, color=color, alpha=0.8, linewidth=1)\n",
    "\n",
    "\n",
    "# 1.Generate data\n",
    "X_data, y_data, mislabel = generate_data(dim=10, num=200) \n",
    "\n",
    "# 2.Split data\n",
    "X_train, y_train, X_test, y_test = random_Split_data(X_data, y_data, rate=0.7)\n",
    "\n",
    "# 3.Train models\n",
    "# model = SVM1(X_train, y_train) \n",
    "model = SVM2(X_train, y_train)  \n",
    "loss_list, times = model.fit()\n",
    "\n",
    "# 4.Print the answers: Accuracy and the number of iterations\n",
    "pre = model.predict(X_test)\n",
    "print(\"Iteration times: {}   Model accuracy: {}     Mislabel: {}\".format(times, model_cmp(pre, y_test), mislabel))\n",
    "\n",
    "# 5.Plot the loss function curve\n",
    "# show(times, loss_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model compare\n",
    "\n",
    "We will compare and evaluate models for gradient descent, minimal sequence optimization, and SVM tools provided by SKlearn.\n",
    "\n",
    "First, we'll test the average accuracy of a single model across multiple datasets. Then, we'll compare the accuracy and training time of the three models on the same dataset.\n",
    "\n",
    "**Note: The functions do NOT pass parameters. In actual testing, you need to set the optimal parameters under the corresponding scale dataset.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm \n",
    "# Only used for model comparison\n",
    "\n",
    "def model_accuracy_ave(model:str = '1', dim = 20, num = 1000, devide_rate = 0.7, total_time = 50, ifsilent = True):   # all possible parameters\n",
    "\n",
    "    model_list = ['1', '2', 'skl']\n",
    "    assert model in model_list, \"unknown model: {}\".format(model)\n",
    "\n",
    "    sum = 0\n",
    "    mis_sum = 0\n",
    "    cnt = 0\n",
    "\n",
    "    if model == '1':\n",
    "        for _ in range(total_time):\n",
    "            X_data, y_data, mislabel = generate_data(dim, num) \n",
    "            X_train, y_train, X_test, y_test = random_Split_data(X_data, y_data, devide_rate)\n",
    "\n",
    "            model = SVM1(X_train, y_train) \n",
    "            model.fit()\n",
    "            pred = model.predict(X_test)\n",
    "            acc = model_cmp(pred, y_test)\n",
    "            sum = sum + acc\n",
    "            mis_sum = mis_sum + mislabel\n",
    "            cnt += 1\n",
    "            \n",
    "            if ifsilent == False:\n",
    "                print(acc)\n",
    "\n",
    "    elif model == '2':\n",
    "        for _ in range(total_time):\n",
    "            X_data, y_data, mislabel = generate_data(dim, num) \n",
    "            X_train, y_train, X_test, y_test = random_Split_data(X_data, y_data, devide_rate)\n",
    "\n",
    "            model = SVM2(X_train, y_train) \n",
    "            model.fit()\n",
    "            pred = model.predict(X_test)\n",
    "            acc = model_cmp(pred, y_test)\n",
    "            sum = sum + acc\n",
    "            mis_sum = mis_sum + mislabel\n",
    "            cnt += 1\n",
    "            \n",
    "            if ifsilent == False:\n",
    "                print(acc)\n",
    "            \n",
    "\n",
    "    elif model == 'skl':\n",
    "        for _ in range(total_time):\n",
    "            X_data, y_data, mislabel = generate_data(dim, num) \n",
    "            X_train, y_train, X_test, y_test = random_Split_data(X_data, y_data, devide_rate)\n",
    "\n",
    "            model = svm.SVC(kernel='linear')\n",
    "            model.fit(X_train, y_train)\n",
    "            pred = model.predict(X_test).reshape(-1, 1)\n",
    "            acc = model_cmp(pred, y_test)\n",
    "            sum = sum + acc\n",
    "            mis_sum = mis_sum + mislabel\n",
    "            cnt += 1\n",
    "            \n",
    "            if ifsilent == False:\n",
    "                print(acc)\n",
    "            \n",
    "    return sum/cnt, mis_sum/cnt\n",
    "\n",
    "\n",
    "# acc, mis = model_accuracy_ave(model='1', total_time=10, dim=10, num=200)\n",
    "# print(\"Model_{}: Ave={}, Mis_Ave={}\".format('1', acc, mis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def model_accuracy_cmp(dim = 20, num = 10000, devide_rate = 0.7, total_time = 50, ifsilent = True):   # all possible parameters\n",
    "\n",
    "    sum = [0, 0, 0]\n",
    "    timer = [0, 0, 0]\n",
    "    mis_sum = 0\n",
    "    i = 0\n",
    "    while i < total_time:\n",
    "        X_data, y_data, mislabel = generate_data(dim, num) \n",
    "        X_train, y_train, X_test, y_test = random_Split_data(X_data, y_data, devide_rate)\n",
    "        \n",
    "        start = time.process_time()\n",
    "        model0 = SVM1(X_train, y_train) \n",
    "        model0.fit()\n",
    "        pred0 = model0.predict(X_test)\n",
    "        sum[0] = sum[0] + model_cmp(pred0, y_test)\n",
    "        end = time.process_time()\n",
    "        timer[0] = timer[0] + end - start\n",
    "        \n",
    "        start = time.process_time()\n",
    "        model1 = SVM2(X_train, y_train) \n",
    "        loss, times = model1.fit()\n",
    "        pred1 = model1.predict(X_test)\n",
    "        sum[1] = sum[1] + model_cmp(pred1, y_test)\n",
    "        end = time.process_time()\n",
    "        timer[1] = timer[1] + end - start\n",
    "\n",
    "        start = time.process_time()\n",
    "        model2 = svm.SVC(kernel='linear')\n",
    "        model2.fit(X_train, y_train.flatten())\n",
    "        pred2 = model2.predict(X_test).reshape(-1, 1)\n",
    "        sum[2] = sum[2] + model_cmp(pred2, y_test) \n",
    "        end = time.process_time()\n",
    "        timer[2] = timer[2] + end - start\n",
    "\n",
    "        mis_sum = mis_sum + mislabel\n",
    "        i += 1\n",
    "    \n",
    "        if ifsilent == False:\n",
    "            print(\"Test times {}: Model_1 accrucy = {}, Model_2 accrucy = {}, Model_skl accurcy = {}\".format(i, sum[0]/i, sum[1]/i, sum[2]/i))\n",
    "        \n",
    "    return i, sum, mis_sum, timer\n",
    "\n",
    "\n",
    "# cnt, sum, missum, times = model_accuracy_cmp(dim=10, num=100, total_time=50)\n",
    "# print(\"Total times: {}\\n    Model_1 accrucy = {}, Model_2 accrucy = {}, Model_skl accurcy = {}\\n    mislabel = {}\".format(cnt, sum[0]/cnt, sum[1]/cnt, sum[2]/cnt, missum/cnt))\n",
    "# print(\"Time cost: model1 = {}, model2 = {}, modelskl={}\".format(times[0]/cnt, times[1]/cnt, times[2]/cnt))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "2469a70536e4d2335a2ea8907942d0699c37342a371ac185bdb5b0aa6f073890"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
