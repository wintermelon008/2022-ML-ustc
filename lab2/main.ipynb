{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In real world, you cannot learn how the data was generated. So do not rely on this function when coding your lab.\n",
    "\n",
    "# In order to make the DEBUG more easy, I add the random seed for option \n",
    "def generate_data(dim = 10, num = 100, random_seed = -1):\n",
    "    if random_seed != -1:\n",
    "        np.random.seed(random_seed)\n",
    "    x = np.random.normal(0, 10, [num, dim])\n",
    "\n",
    "    if random_seed != -1:\n",
    "        np.random.seed(random_seed)\n",
    "    coef = np.random.uniform(-1, 1, [dim, 1])\n",
    "\n",
    "    pred = np.dot(x, coef)\n",
    "    pred_n = (pred - np.mean(pred)) / np.sqrt(np.var(pred))\n",
    "    label = np.sign(pred_n)\n",
    "\n",
    "    if random_seed != -1:\n",
    "        np.random.seed(random_seed)\n",
    "    mislabel_value = np.random.uniform(0, 1, num)\n",
    "    mislabel = 0\n",
    "\n",
    "    for i in range(num):\n",
    "        if np.abs(pred_n[i]) < 1 and mislabel_value[i] > 0.9 + 0.1 * np.abs(pred_n[i]):\n",
    "            label[i] *= -1\n",
    "            mislabel += 1\n",
    "    return x, label, mislabel/num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 10.57709908  -6.00867717  -4.05957033   2.86962942  -0.9660421\n",
      " -12.88587278   6.35784024 -16.63497723  18.11501855]\n",
      "[[-1.]\n",
      " [ 1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [ 1.]\n",
      " [-1.]\n",
      " [ 1.]\n",
      " [-1.]\n",
      " [-1.]]\n",
      "0.02\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# example\n",
    "x, y, mr = generate_data(5, 100)\n",
    "print(x[1:10, 1])\n",
    "print(y[1:10])\n",
    "print(mr)\n",
    "print(type(x))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# write your model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can do anything necessary about the model\n",
    "def my_max(a, b):\n",
    "    return a if a > b else b\n",
    "\n",
    "def find_zero(a, b):\n",
    "    return 0 if a == 0 else b\n",
    "\n",
    "def array_max(a:np.ndarray, b:np.ndarray)->np.ndarray:\n",
    "    func_ = np.frompyfunc(my_max, 2, 1)\n",
    "    return(func_(a, b))\n",
    "\n",
    "def array_find0(a:np.ndarray, b:np.ndarray) -> np.ndarray:\n",
    "    func_ = np.frompyfunc(find_zero, 2, 1)\n",
    "    return(func_(a, b))\n",
    "\n",
    "class SVM1:\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        You can add some other parameters, which I think is not necessary\n",
    "        \"\"\"\n",
    "\n",
    "    def fit(self, X:np.ndarray, y:np.ndarray, gamma = 0.25, lr = 0.002, tol=1e-4, max_times=100, silent = True):\n",
    "        \"\"\"\n",
    "        ---\n",
    "        parameters:\n",
    "        ---\n",
    "            X: Data characteristics\n",
    "            y: Data category\n",
    "            gamma: Loss function parameter. Default 0.001\n",
    "            lr: Learning rate. Default 0.01\n",
    "            max_times: The maximum times of training iterations. Default 100\n",
    "            tol: 梯度下降的阈值 Defalut 1\n",
    "        \"\"\"\n",
    "        m, n = X.shape\n",
    "        self.w = np.zeros((n + 1, 1))\n",
    "\n",
    "        temp_1 = np.ones((m, 1))\n",
    "        X_hat:np.ndarray = np.c_[X, temp_1]\n",
    "\n",
    "        temp_0 = np.zeros((m, 1))\n",
    "        loss_list = []\n",
    "        y_diag = np.diag(y.reshape(-1))\n",
    "\n",
    "        if (silent):\n",
    "            for times in range(max_times):\n",
    "                xi = array_max(temp_0, 1 - (y_diag @ X_hat @ self.w))\n",
    "                loss = 0.5 * (self.w.T @ self.w)[0][0] + gamma * (xi.sum())\n",
    "                \n",
    "                y_bar = array_find0(xi , y)\n",
    "\n",
    "                delta_1 = self.w - gamma * (X_hat.T @ y_bar)\n",
    "                \n",
    "                if times >= 2 and abs(loss_list[-1] - loss) < tol:\n",
    "                    loss_list.append(loss)\n",
    "                    break\n",
    "\n",
    "                self.w = self.w - lr * delta_1\n",
    "                loss_list.append(loss)\n",
    "        else:\n",
    "            for times in range(max_times):\n",
    "                xi = array_max(temp_0, 1 - (y_diag @ X_hat @ self.w))\n",
    "                loss = 0.5 * (self.w.T @ self.w)[0][0] + gamma * (xi.sum())\n",
    "                \n",
    "                y_bar = array_find0(xi , y)\n",
    "\n",
    "                delta_1 = self.w - gamma * (X_hat.T @ y_bar)\n",
    "                \n",
    "                if times >= 2 and abs(loss_list[-1] - loss) < tol:\n",
    "                    loss_list.append(loss)\n",
    "                    break\n",
    "\n",
    "                if (times % 10 == 0):\n",
    "                    print(\"Current times: {}, loss is {}\".format(times, loss))\n",
    "\n",
    "                self.w = self.w - lr * delta_1\n",
    "                loss_list.append(loss)\n",
    "\n",
    "        return loss_list, times\n",
    "            \n",
    "\n",
    "        \n",
    "    def predict(self, X:np.ndarray):\n",
    "        \"\"\"\n",
    "        Use the trained model to generate prediction probabilities on a new\n",
    "        collection of data points.\n",
    "        \"\"\"\n",
    "\n",
    "        m, n = X.shape\n",
    "        temp_1 = np.ones(m)\n",
    "        X_hat:np.ndarray = np.c_[X, temp_1]\n",
    "\n",
    "        temp = X_hat @ self.w\n",
    "        ans = []\n",
    "        for i in range(m):\n",
    "            if temp[i] > 0:\n",
    "                ans.append(1)\n",
    "            else:\n",
    "                ans.append(-1)\n",
    "        \n",
    "        return np.array(ans).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can do anything necessary about the model\n",
    "from numpy import double\n",
    "\n",
    "\n",
    "class SVM2:\n",
    "    def __init__(self, X:np.ndarray, y:np.ndarray):\n",
    "        \"\"\"\n",
    "        You can add some other parameters, which I think is not necessary\n",
    "        \"\"\"\n",
    "        m, _ = X.shape\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        \n",
    "        self.alpha = np.zeros((m, 1))\n",
    "        self.b = 0\n",
    "        self.err = np.zeros((m, 1))\n",
    "        self._update_e()\n",
    "\n",
    "    \n",
    "    def _x(self, X_index):\n",
    "        return self.X[X_index, :]\n",
    "    \n",
    "    def _K(self, X1_index, X2_index = -1):\n",
    "        if X2_index == -1:\n",
    "            X2_index = X1_index\n",
    "        return (self.X[X1_index, :] @ self.X[X2_index, :].T)\n",
    "\n",
    "    def _y(self, y_index):\n",
    "        return (self.y[y_index, :])[0]\n",
    "\n",
    "    def _a(self, a_index):\n",
    "        return (self.alpha[a_index, :])[0]\n",
    "\n",
    "    def _e(self, e_index):\n",
    "        return (self.err[e_index, :])[0]\n",
    "\n",
    "    def _func(self, X_index):\n",
    "        alpha_y = self.alpha * self.y\n",
    "        return (alpha_y.T @ self.X @ self._x(X_index).T)[0] + self.b\n",
    "        \n",
    "    def _error(self, X_index):\n",
    "        return self._func(X_index) - self._y(X_index)\n",
    "\n",
    "\n",
    "    def _cut(self, a1_index, a2_index, a2_uncut, gamma) -> (float | bool):\n",
    "        if self._y(a1_index) != self._y(a2_index):\n",
    "            low = max(0, self._a(a2_index) - self._a(a1_index))\n",
    "            high = min(gamma, gamma + self._a(a2_index) - self._a(a1_index))\n",
    "        else:\n",
    "            low = max(0, self._a(a2_index) + self._a(a1_index) - gamma)\n",
    "            high = min(gamma, self._a(a2_index) + self._a(a1_index))\n",
    "\n",
    "        if high == low:\n",
    "            return False\n",
    "        \n",
    "        if a2_uncut > high:\n",
    "            return high\n",
    "        elif a2_uncut < low:\n",
    "            return low\n",
    "        return a2_uncut\n",
    "\n",
    "\n",
    "    def _update_alpha(self, a1_index, a2_index, gamma):\n",
    "\n",
    "        eta = self._K(a1_index) + self._K(a2_index) - 2 * self._K(a1_index, a2_index)\n",
    "\n",
    "        if eta > 0:\n",
    "            a2_uncut = self._a(a2_index) + self._y(a2_index) * (self._e(a1_index) - self._e(a2_index)) / eta\n",
    "        else:\n",
    "            # print(\"Eta <= 0\")\n",
    "            return False\n",
    "        \n",
    "        alpha2_new = self._cut(a1_index, a2_index, a2_uncut, gamma)\n",
    "        if (alpha2_new == False):\n",
    "            # print(\"Low == High\")\n",
    "            return False\n",
    "        \n",
    "        if (abs(self._a(a2_index) - alpha2_new) <1e-3):\n",
    "            # print(\"Alpha2 moves too slow\")\n",
    "            return False\n",
    "\n",
    "        alpha1_new = self._a(a1_index) + self._y(a1_index) * \\\n",
    "                                  self._y(a2_index) * (self._a(a2_index) - \\\n",
    "                                  alpha2_new)\n",
    "        self._update_b(a1_index, a2_index, alpha1_new, alpha2_new, gamma)\n",
    "\n",
    "        self.alpha[a1_index] = alpha1_new\n",
    "        self.alpha[a2_index] = alpha2_new\n",
    "\n",
    "        self._update_e()\n",
    "\n",
    "        return True\n",
    "\n",
    "\n",
    "    def _update_b(self, a1_index, a2_index, a1_new, a2_new, gamma):\n",
    "        alpha_1 = self._a(a1_index) \n",
    "        alpha_2 = self._a(a2_index) \n",
    "\n",
    "        b1 = -self._e(a1_index) - \\\n",
    "                self._y(a1_index) * self._K(a1_index) * (a1_new - alpha_1) - \\\n",
    "                self._y(a2_index) * self._K(a2_index, a1_index) * (a2_new - alpha_2) + \\\n",
    "                self.b\n",
    "        if 0 < alpha_1 < gamma:\n",
    "            self.b = b1\n",
    "            return\n",
    "      \n",
    "        b2 = -self._e(a2_index) - \\\n",
    "                self._y(a1_index) * self._K(a1_index, a2_index) * (a1_new - alpha_1) - \\\n",
    "                self._y(a2_index) * self._K(a2_index) * (a2_new - alpha_2) + \\\n",
    "                self.b\n",
    "        if 0 < alpha_2 < gamma:\n",
    "            self.b = b2\n",
    "            return\n",
    "        \n",
    "        self.b = 0.5 * (b1 + b2)\n",
    "        return\n",
    "\n",
    "    def _update_e(self):\n",
    "        m, _ = self.X.shape\n",
    "        for i in range(m):\n",
    "            self.err[i] = self._error(i) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def fit(self, gamma = 1, lr = 0.01, tol=1, max_times = 100, silent = True, epslion = 0):\n",
    "        \"\"\"\n",
    "        Fit the coefficients via your methods\n",
    "        \"\"\"\n",
    "        m, n = self.X.shape\n",
    "\n",
    "        loss_list = []\n",
    "        times = 0\n",
    "        \n",
    "\n",
    "        while times < max_times:\n",
    "            alpha_y = self.alpha * self.y\n",
    "            loss = self.alpha.sum() - 0.5 * (alpha_y.T @ self.X @ self.X.T @ alpha_y)[0][0]\n",
    "\n",
    "            i_list = []\n",
    "            i_dict = {}\n",
    "\n",
    "            for i in range(m):\n",
    "                if (self._a(i) < gamma and self._e(i) < -epslion) or \\\n",
    "                   (self._a(i) > 0 and self._e(i) > epslion):\n",
    "                    val = abs(self._e(i) - epslion)\n",
    "                    i_list.append(val)\n",
    "                    i_dict[val] = i\n",
    "                # temp = self._y(i) * self._func(i)\n",
    "                # if self._a(i) <= 0 and temp < 1 - epslion:\n",
    "                #     val = 1 - epslion - temp\n",
    "                #     i_list.append(val)\n",
    "                #     i_dict[val] = i\n",
    "\n",
    "                # elif self._a(i) >= gamma and temp > 1 + epslion:\n",
    "                #     val = 1 + epslion - temp\n",
    "                #     i_list.append(val)\n",
    "                #     i_dict[val] = i\n",
    "\n",
    "                # elif abs(temp - 1) > epslion:\n",
    "                #     val = abs(temp - 1) - epslion\n",
    "                #     i_list.append(val)\n",
    "                #     i_dict[val] = i\n",
    "\n",
    "            if len(i_list) == 0:\n",
    "                loss_list.append(loss)\n",
    "                break\n",
    "\n",
    "            i_list.sort()\n",
    "            while len(i_list) > 0:\n",
    "                a1 = i_dict[i_list.pop()]\n",
    "                e1 = self._e(a1)\n",
    "\n",
    "                err_dict = []\n",
    "                err_list = []\n",
    "                for i in self.err.tolist():\n",
    "                    err_list.append(i[0])\n",
    "                # print(err_list)\n",
    "                for index, value in enumerate(err_list):\n",
    "                    err_dict.append((value, index))\n",
    "                err_dict.sort(key=takefirst)\n",
    "                k = 0\n",
    "    \n",
    "                if e1 > 0:\n",
    "                    while k < m:\n",
    "                        a2 = err_dict[k][1]\n",
    "                        if a1 != a2 and self._update_alpha(a1, a2, gamma):\n",
    "                            break\n",
    "                        k += 1\n",
    "                else:\n",
    "                    while k < m:\n",
    "                        a2 = err_dict[-1 - k][1]\n",
    "                        if a1 != a2 and self._update_alpha(a1, a2, gamma):\n",
    "                            break\n",
    "                        k += 1\n",
    "\n",
    "                if k == m:\n",
    "                    continue  # change i\n",
    "                else:\n",
    "                    break\n",
    "            \n",
    "\n",
    "            if times >= 2 and abs(loss_list[-1] - loss) < tol:\n",
    "                loss_list.append(loss)\n",
    "                break\n",
    "\n",
    "            loss_list.append(loss)\n",
    "            times += 1\n",
    "\n",
    "        if times == max_times:\n",
    "            times -= 1\n",
    "        return loss_list, times\n",
    "\n",
    "\n",
    "    def predict(self, X:np.ndarray):\n",
    "        \"\"\"\n",
    "        Use the trained model to generate prediction probabilities on a new\n",
    "        collection of data points.\n",
    "        \"\"\"\n",
    "\n",
    "        m, n = X.shape\n",
    "\n",
    "        ans = []\n",
    "        for i in range(m):\n",
    "            alpha_y = self.alpha * self.y\n",
    "            temp = (alpha_y.T @ self.X @ X[i, :].T)[0] + self.b\n",
    "            if temp > 0:\n",
    "                ans.append(1)\n",
    "            else:\n",
    "                ans.append(-1)\n",
    "        \n",
    "        return np.array(ans).reshape(-1, 1)\n",
    "\n",
    "def takefirst(elm):\n",
    "    return elm[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# construct and train your models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# generate data\n",
    "X_data, y_data, mislabel = generate_data(dim=20, num=10000) \n",
    "\n",
    "# split data\n",
    "def random_Split_data(X: np.ndarray, y:np.ndarray, rate = 0.7, random_seed: int = -1):\n",
    "    data: np.ndarray = np.hstack((X, y))\n",
    "    m, n = data.shape\n",
    "    if random_seed != -1:\n",
    "        np.random.seed(abs(random_seed))\n",
    "    np.random.shuffle(data)\n",
    "    \n",
    "    row_split = int(m * rate)\n",
    "    X_train = data[0: row_split, 0: -1]\n",
    "    y_train = data[0: row_split, -1: ]\n",
    "    X_test = data[row_split: m, 0: -1]\n",
    "    y_test = data[row_split: m, -1: ]\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "\n",
    "X_train, y_train, X_test, y_test = random_Split_data(X_data, y_data, rate=0.7)\n",
    "\n",
    "\n",
    "# constrcut model and train (remember record time)\n",
    "model1 = SVM1() \n",
    "loss_list, times = model1.fit(X_train, y_train, gamma = 0.005, lr = 0.002, tol=1e-4, max_times=100)\n",
    "# loss_list, times = model1.fit(X_train, y_train, tol=1e-2)\n",
    "# print(model1.w)\n",
    "\n",
    "# print(times)\n",
    "# print(loss_list)\n",
    "\n",
    "# model2 = SVM2(X_train, y_train)\n",
    "# loss_list, times = model2.fit(gamma = 0.08, tol = 1e-5, max_times=800, epslion=0.05)\n",
    "\n",
    "# print(model2.alpha)\n",
    "# print(loss_list)\n",
    "# print(times)\n",
    "# print(len(loss_list))\n",
    "\n",
    "\n",
    "# print(X_train.shape)\n",
    "# print(y_train.shape)\n",
    "# m = SVM2(X_train, y_train)\n",
    "# print(m.err)\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "def show(times, loss, color = '#4169E1', start=0, end=2000):\n",
    "    x_axis_data = list(range(times + 1))[start:end]\n",
    "    y_axis_data = loss[start:end]\n",
    "    plt.plot(x_axis_data, y_axis_data, color=color, alpha=0.8, linewidth=1)\n",
    "\n",
    "\n",
    "show(times, loss_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# predict and compare your results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 1)\n",
      "0.9513333333333334\n",
      "0.0362\n"
     ]
    }
   ],
   "source": [
    "# make prediction\n",
    "\n",
    "def model_cmp(y_pre:np.ndarray, y_test:np.ndarray):\n",
    "    # y should be in shape m x 1\n",
    "    corr = 0\n",
    "    sum = 0\n",
    "    m, n = y_pre.shape\n",
    "    \n",
    "    for i in range(m):\n",
    "        if y_pre[i] == y_test[i]:\n",
    "            corr += 1\n",
    "        sum += 1\n",
    "    return corr/sum\n",
    "\n",
    "# pred = model1.predict()\n",
    "\n",
    "# compared with answer\n",
    "\n",
    "# compare each methods\n",
    "# print(X_test.shape)\n",
    "pre = model1.predict(X_test)\n",
    "print(pre.shape)\n",
    "print(model_cmp(pre, y_test))\n",
    "print(mislabel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the model accuracy on average\n",
    "\n",
    "from sklearn import svm\n",
    "\n",
    "def model_accuracy_ave(model:str = '1', dim = 20, num = 10000, devide_rate = 0.7, total_time = 50):   # all possible parameters\n",
    "\n",
    "    model_list = ['1', '2', 'skl']\n",
    "    assert model in model_list, \"unknown model: {}\".format(model)\n",
    "\n",
    "    sum = 0\n",
    "    mis_sum = 0\n",
    "    cnt = 0\n",
    "\n",
    "    if model == '1':\n",
    "        for _ in range(total_time):\n",
    "            X_data, y_data, mislabel = generate_data(dim, num) \n",
    "            X_train, y_train, X_test, y_test = random_Split_data(X_data, y_data, devide_rate)\n",
    "\n",
    "            model = SVM1() \n",
    "            model.fit(X_train, y_train)\n",
    "            pred = model.predict(X_test)\n",
    "\n",
    "            sum = sum + model_cmp(pred, y_test)\n",
    "            mis_sum = mis_sum + mislabel\n",
    "            cnt += 1\n",
    "            # print(model_cmp(pred, y_test))\n",
    "\n",
    "    elif model == '2':\n",
    "        i = 0\n",
    "        while i < total_time:\n",
    "            X_data, y_data, mislabel = generate_data(dim, num) \n",
    "            X_train, y_train, X_test, y_test = random_Split_data(X_data, y_data, devide_rate)\n",
    "\n",
    "            model = SVM2(X_train, y_train) \n",
    "            loss, times = model.fit(gamma = 0.1, tol = 1e-3, max_times=800, epslion=0.2)\n",
    "\n",
    "            if times < 100:\n",
    "                continue\n",
    "\n",
    "            pred = model.predict(X_test)\n",
    "            temp = model_cmp(pred, y_test)\n",
    "\n",
    "               \n",
    "            sum += temp\n",
    "            mis_sum = mis_sum + mislabel\n",
    "            cnt += 1\n",
    "            print(temp)\n",
    "            i += 1\n",
    "\n",
    "    elif model == 'skl':\n",
    "        for _ in range(total_time):\n",
    "            X_data, y_data, mislabel = generate_data(dim, num) \n",
    "            X_train, y_train, X_test, y_test = random_Split_data(X_data, y_data, devide_rate)\n",
    "\n",
    "            model = svm.SVC(kernel='linear')\n",
    "            model.fit(X_train, y_train)\n",
    "            pred = model.predict(X_test).reshape(-1, 1)\n",
    "\n",
    "            sum += model_cmp(pred, y_test)\n",
    "            mis_sum = mis_sum + mislabel\n",
    "            cnt += 1\n",
    "            # print(model_cmp(pred, y_test))\n",
    "\n",
    "\n",
    "    # print(cnt)\n",
    "    return sum/cnt, mis_sum/cnt\n",
    "# print(\"Model_{}:Ave={}\".format('2', model_accuracy_ave(dim=5, num=100, model='2', total_time=50)))\n",
    "# acc, mis = model_accuracy_ave(model='2', total_time=50, dim=10, num=200)\n",
    "# print(\"Model_{}:Ave={}, Mis_Ave={}\".format('2', acc, mis))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def model_accuracy_cmp(dim = 20, num = 10000, devide_rate = 0.7, total_time = 50):   # all possible parameters\n",
    "\n",
    "   \n",
    "\n",
    "    sum = [0, 0, 0]\n",
    "    timer = [0, 0, 0]\n",
    "    mis_sum = 0\n",
    "    i = 0\n",
    "\n",
    "    while i < total_time:\n",
    "        X_data, y_data, mislabel = generate_data(dim, num) \n",
    "        X_train, y_train, X_test, y_test = random_Split_data(X_data, y_data, devide_rate)\n",
    "\n",
    "        \n",
    "        start = time.process_time()\n",
    "        model1 = SVM2(X_train, y_train) \n",
    "        loss, times = model1.fit(gamma = 0.08, tol = 1e-5, max_times=800, epslion=0.05)\n",
    "        if times < 100:\n",
    "            continue\n",
    "        pred1 = model1.predict(X_test)\n",
    "        sum[1] = sum[1] + model_cmp(pred1, y_test)\n",
    "        end = time.process_time()\n",
    "        timer[1] = timer[1] + end - start\n",
    "\n",
    "\n",
    "        start = time.process_time()\n",
    "        model0 = SVM1() \n",
    "        model0.fit(X_train, y_train)\n",
    "        pred0 = model0.predict(X_test)\n",
    "        sum[0] = sum[0] + model_cmp(pred0, y_test)\n",
    "        end = time.process_time()\n",
    "        timer[0] = timer[0] + end - start\n",
    "\n",
    "\n",
    "        start = time.process_time()\n",
    "        model2 = svm.SVC(kernel='linear')\n",
    "        model2.fit(X_train, y_train)\n",
    "        pred2 = model2.predict(X_test).reshape(-1, 1)\n",
    "        sum[2] = sum[2] + model_cmp(pred2, y_test) \n",
    "        end = time.process_time()\n",
    "        timer[2] = timer[2] + end - start\n",
    "\n",
    "        mis_sum = mis_sum + mislabel\n",
    "        i += 1\n",
    "        # print(sum)\n",
    "        # print(timer)\n",
    "        \n",
    "\n",
    "\n",
    "    return i, sum, mis_sum, timer\n",
    "\n",
    "# cnt, sum, missum, times = model_accuracy_cmp(dim=10, num=100, total_time=50)\n",
    "# print(\"Total times: {}\\n    Model_1 accrucy = {}, Model_2 accrucy = {}, Model_skl accurcy = {}\\n    mislabel = {}\".format(cnt, sum[0]/cnt, sum[1]/cnt, sum[2]/cnt, missum/cnt))\n",
    "# print(\"Time cost: model1 = {}, model2 = {}, modelskl={}\".format(times[0]/cnt, times[1]/cnt, times[2]/cnt))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "2469a70536e4d2335a2ea8907942d0699c37342a371ac185bdb5b0aa6f073890"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
